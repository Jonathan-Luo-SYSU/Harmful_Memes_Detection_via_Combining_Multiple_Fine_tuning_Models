{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f838f4-a22a-4bd6-89f4-9821b8061076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 21:38:23,207 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "Downloading [chat_template.json]: 100%|██████████| 1.03k/1.03k [00:00<00:00, 3.73kB/s]\n",
      "Downloading [config.json]: 100%|██████████| 1.17k/1.17k [00:00<00:00, 2.83kB/s]\n",
      "Downloading [configuration.json]: 100%|██████████| 76.0/76.0 [00:00<00:00, 187B/s]\n",
      "Downloading [generation_config.json]: 100%|██████████| 272/272 [00:00<00:00, 537B/s]\n",
      "Downloading [LICENSE]: 100%|██████████| 11.1k/11.1k [00:00<00:00, 38.2kB/s]\n",
      "Downloading [merges.txt]: 100%|██████████| 1.59M/1.59M [00:00<00:00, 3.13MB/s]\n",
      "Downloading [model-00001-of-00002.safetensors]: 100%|██████████| 3.71G/3.71G [00:24<00:00, 165MB/s] \n",
      "Downloading [model-00002-of-00002.safetensors]: 100%|██████████| 410M/410M [00:05<00:00, 82.4MB/s] \n",
      "Downloading [model.safetensors.index.json]: 100%|██████████| 55.1k/55.1k [00:00<00:00, 111kB/s]\n",
      "Downloading [preprocessor_config.json]: 100%|██████████| 347/347 [00:00<00:00, 1.17kB/s]\n",
      "Downloading [README.md]: 100%|██████████| 16.2k/16.2k [00:00<00:00, 52.8kB/s]\n",
      "Downloading [tokenizer.json]: 100%|██████████| 6.70M/6.70M [00:00<00:00, 11.8MB/s]\n",
      "Downloading [tokenizer_config.json]: 100%|██████████| 4.09k/4.09k [00:00<00:00, 12.1kB/s]\n",
      "Downloading [vocab.json]: 100%|██████████| 2.65M/2.65M [00:00<00:00, 5.98MB/s]\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6103f0e6f9fc4515a1c79db4282c656c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from modelscope import snapshot_download, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq, Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "import torch\n",
    "\n",
    "# 在modelscope上下载Qwen2-VL模型到本地目录下\n",
    "model_dir = snapshot_download(\"Qwen/Qwen2-VL-2B-Instruct\", cache_dir=\"./\", revision=\"master\")\n",
    "\n",
    "# 使用Transformers加载模型权重\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./Qwen/Qwen2-VL-2B-Instruct/\", use_fast=False, trust_remote_code=True)\n",
    "# 特别的，Qwen2-VL-2B-Instruct模型需要使用Qwen2VLForConditionalGeneration来加载\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\"./Qwen/Qwen2-VL-2B-Instruct/\", device_map=\"auto\", torch_dtype=torch.bfloat16, trust_remote_code=True,)\n",
    "model.enable_input_require_grads()  # 开启梯度检查点时，要执行该方法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62615708-5cd0-41f9-ba3a-71f3125bc02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 21:41:27,483 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "Downloading [chat_template.json]: 100%|██████████| 1.03k/1.03k [00:00<00:00, 3.35kB/s]\n",
      "Downloading [config.json]: 100%|██████████| 1.17k/1.17k [00:00<00:00, 3.63kB/s]\n",
      "Downloading [configuration.json]: 100%|██████████| 76.0/76.0 [00:00<00:00, 175B/s]\n",
      "Downloading [generation_config.json]: 100%|██████████| 244/244 [00:00<00:00, 456B/s]\n",
      "Downloading [LICENSE]: 100%|██████████| 11.1k/11.1k [00:00<00:00, 38.0kB/s]\n",
      "Downloading [merges.txt]: 100%|██████████| 1.59M/1.59M [00:00<00:00, 4.09MB/s]\n",
      "Downloading [model-00001-of-00005.safetensors]: 100%|██████████| 3.63G/3.63G [00:26<00:00, 149MB/s] \n",
      "Downloading [model-00002-of-00005.safetensors]: 100%|██████████| 3.60G/3.60G [00:27<00:00, 142MB/s] \n",
      "Downloading [model-00003-of-00005.safetensors]: 100%|██████████| 3.60G/3.60G [00:41<00:00, 93.9MB/s]\n",
      "Downloading [model-00004-of-00005.safetensors]: 100%|██████████| 3.60G/3.60G [00:24<00:00, 157MB/s] \n",
      "Downloading [model-00005-of-00005.safetensors]: 100%|██████████| 1.02G/1.02G [00:18<00:00, 57.8MB/s]\n",
      "Downloading [model.safetensors.index.json]: 100%|██████████| 55.1k/55.1k [00:00<00:00, 163kB/s]\n",
      "Downloading [preprocessor_config.json]: 100%|██████████| 347/347 [00:00<00:00, 1.07kB/s]\n",
      "Downloading [README.md]: 100%|██████████| 17.7k/17.7k [00:00<00:00, 52.5kB/s]\n",
      "Downloading [tokenizer.json]: 100%|██████████| 6.70M/6.70M [00:00<00:00, 11.3MB/s]\n",
      "Downloading [tokenizer_config.json]: 100%|██████████| 4.09k/4.09k [00:00<00:00, 12.6kB/s]\n",
      "Downloading [vocab.json]: 100%|██████████| 2.65M/2.65M [00:00<00:00, 4.98MB/s]\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9e450f657b48728cec471d8906d842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from modelscope import snapshot_download, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq, Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "import torch\n",
    "\n",
    "# 在modelscope上下载Qwen2-VL模型到本地目录下\n",
    "model_dir = snapshot_download(\"Qwen/Qwen2-VL-7B-Instruct\", cache_dir=\"./\", revision=\"master\")\n",
    "\n",
    "# 使用Transformers加载模型权重\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./Qwen/Qwen2-VL-7B-Instruct/\", use_fast=False, trust_remote_code=True)\n",
    "# 特别的，Qwen2-VL-2B-Instruct模型需要使用Qwen2VLForConditionalGeneration来加载\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\"./Qwen/Qwen2-VL-7B-Instruct/\", device_map=\"auto\", torch_dtype=torch.bfloat16, trust_remote_code=True,)\n",
    "model.enable_input_require_grads()  # 开启梯度检查点时，要执行该方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd61d37-2a3d-4c07-8fe8-bd9fc5198822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
