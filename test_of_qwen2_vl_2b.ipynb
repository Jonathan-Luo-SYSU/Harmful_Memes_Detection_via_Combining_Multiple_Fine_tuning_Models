{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a3097c-4464-4814-a771-b97631d8285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "## 获取图片编号\n",
    "import os\n",
    "\n",
    "test_id = []\n",
    "\n",
    "def get_id():\n",
    "    folder_path = 'datasets/train'\n",
    "    file_names = os.listdir(folder_path)\n",
    "    # print(file_names[0])\n",
    "    for i in range(1, len(file_names)):\n",
    "        # print(file_names[i].split('.')[0])\n",
    "        test_id.append(file_names[i].split('.')[0])\n",
    "get_id()\n",
    "test_id.sort()\n",
    "# print(test_id)\n",
    "print(len(test_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f79ad8f-3e6c-4a79-b676-fc9adb474609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "## 获取真实准确率\n",
    "import json\n",
    "\n",
    "real_data = []\n",
    "\n",
    "# 示例json文件路径\n",
    "file_path = \"data_vl_train.json\"\n",
    "# 打开并读取JSON文件\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    # print(data)\n",
    "\n",
    "\n",
    "# 打印读取的数据\n",
    "for i in range(0, len(data)):\n",
    "    # print(data[i]['conversations'][0]['value'].split('/')[2].split('.')[0])\n",
    "    # print(data[i]['conversations'][1]['value'])\n",
    "    real_data.append( data[i]['conversations'][1]['value'] )\n",
    "    \n",
    "print(len(real_data))\n",
    "# print(real_data)\n",
    "\n",
    "\n",
    "# 示例json文件路径\n",
    "file_path = \"data_vl_test.json\"\n",
    "# 打开并读取JSON文件\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    # print(data)\n",
    "\n",
    "\n",
    "# 打印读取的数据\n",
    "for i in range(0, len(data)):\n",
    "    # print(data[i]['conversations'][0]['value'].split('/')[2].split('.')[0])\n",
    "    # print(data[i]['conversations'][1]['value'])\n",
    "    real_data.append( data[i]['conversations'][1]['value'] )\n",
    "    \n",
    "print(len(real_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b686758b-f1af-450d-8f40-543ec952a8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5054b2e1885457db74e70cae7f5a62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv3d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[['1'], ['1'], ['0'], ['1'], ['1'], ['1'], ['1'], ['1'], ['0'], ['1'], ['1'], ['1'], ['0'], ['1'], ['1'], ['1'], ['0'], ['0'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['0'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['0'], ['1'], ['0'], ['1'], ['1'], ['1'], ['0'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['1'], ['0'], ['0']]\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "\n",
    "# 设定设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载模型并移动到目标设备\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ").to(device)\n",
    "\n",
    "# 加载处理器\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
    "\n",
    "def fun(id):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": \"datasets/train/\" + id + \".png\",\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": \"Please analyze the content of the picture and the text in the picture. If you think the combination of the content and the text is harmful (such as violence, pornography, discrimination and other harmful behaviors), please output 1; if you think the combination is harmless, please output 0::\"},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Preparation for inference\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    \n",
    "    # 确保图像和视频输入也被移动到目标设备\n",
    "    if isinstance(image_inputs, torch.Tensor):\n",
    "        image_inputs = image_inputs.to(device)\n",
    "    if isinstance(video_inputs, torch.Tensor):\n",
    "        video_inputs = video_inputs.to(device)\n",
    "    \n",
    "    # 处理文本、图像和视频输入，并确保它们在相同设备上\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    \n",
    "    # 将所有输入张量移动到目标设备\n",
    "    for key in inputs:\n",
    "        if isinstance(inputs[key], torch.Tensor):\n",
    "            inputs[key] = inputs[key].to(device)\n",
    "    \n",
    "    # Inference: Generation of the output\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "    \n",
    "    # 确保生成的ID也在同一设备上\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    return output_text\n",
    "    # print(output_text)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "raw_test = []\n",
    "\n",
    "def start_raw_test():\n",
    "    for i in range(0, 100):\n",
    "        # print(file_names[i].split('.')[0])\n",
    "        raw_test.append(fun(test_id[i]))\n",
    "\n",
    "start_raw_test()\n",
    "print(len(raw_test))\n",
    "\n",
    "print(raw_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f753036a-818a-45ac-bffa-73d51e68cc2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc656adfc6e4a3db173599bac4b5e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[[\"when you're feeling horny\\nasf but your habibi is on periods let's try a goat\"], ['meanwhile at the isis strip club'], ['when your human says\\n\"who\\'s a good girl?\"\\nand you already know it\\'s you'], ['and that was the last\\nnativity play my son was\\ninvited to take part in.'], [\"you can't be racist if there is no other race\"], ['when your debit card\\ndecline at the abortion\\nclinic\\n\\nand they have to put\\nthe baby back in'], [' ladies! if your man is offended by this\\nhe is a faggot. end of story'], [\"you're a special kinda nuts\\naren't you?\"], ['father and daughter bonding time is the best\\nlike and share if you agree'], ['kermit the frog\\ndefinitely not a muslim'], ['how you guys think you looks like\\nbut when pados wale pandit jee sees you\\ntaba renso'], ['the text in the picture is:\\n\\nif you think t willl stop\\neating palony and viannas\\nvoetsek!!!'], ['a smile is worth a\\nthousand words'], ['The text in the picture is:\\n\\n\"CAFE\\nmuslims offend me'], ['when you forget to\\nwash your hands'], ['The text in the picture is:\\n\\n- \"men wearing dresses and molesting our children?\"\\n- \"the word you\\'re looking for is clergy, not transgender\"\\n\\nThe text is not harmful.'], ['the great train robbers'], ['when your world cup team\\nscores a goal'], [\"The text in the picture is:\\n\\ni'm not sick, i'm twisted\\nsick makes it sound\\nlike there's a cure\"], [\"the text in the picture is:\\n\\nsaddle up motherfuckers\\nit's time to play cowboys\"], ['meanwhile at the isis strip club'], [\"girl you're so special\\ni'm gonna give you a gold star\"], ['The text in the picture is as follows:\\n\\n- area 51\\n- naruto runners\\n- Naruto runners\\n- let me iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii'], ['and that was the last nativity play my son was invited to take part in'], ['american teenage girl\\nvisiting the children of africa'], ['my body my choice\\nAbortion'], ['The text in the picture is:\\n\\n- confession-every sunday around brunch time\\n- i take my cat to the mall and make people take pictures of us'], ['hello jesus\\nthanks for making a\\nway!'], ['i just found out mexican babies come out just like the food'], ['when you want to nap\\nafter a long day of mudding'], [\"when the school shooter\\naccidentally shoots the autistic kid\\nbut doesn't know that the tard\\nstrength makes him impervious to\\nbullets\"], ['The text in the picture is:\\n\\n-im long and strong\\nand down to get the goat hump on'], ['the feeling after\\na long day at work'], ['they see them rollin..... they hating...'], [\"trust me...\\nthey're re all terrorists\"], ['there is difference between violating muslims and other muslims\\ndont get confused'], [\"the text in the picture is:\\n\\nit's a great day\\nto be a honky!\"], ['assad: my son exploded better than yours, lol\\nhamid:'], ['when you punch the muslim kid so hard that he starts having seizures and fucking dies\\nthe bomb has been defused'], ['in my country this headdress is common to wear if you want to.\\nhere in other countries i am also free to wear it if i want to'], ['last time muslims invaded europe\\nvlad stuck poles up their\\nasses and made a fucking forest\\nbe like vlad'], ['The text in the picture is:\\n\\n\"im confident in my own skin\"\\n\\nThe text is not harmful.'], [\"the text in the picture is:\\n\\nfeeling bored, let's go to a mosque\"], [\"when you forget\\nyou're retarded\\nSIRIUS-96\\nSIRIUS-96\\nSIRIUS-96\\nSIRIUS-96\\nSIRIUS-96\\nSIRIUS-96\\nSIRIUS-96\\nSIRIUS-96\\nSIRIUS-96\\nSIRIUS-96\\nSIRIUS-96\\nSIRIUS-96\\nSIRIUS-96\\nSIRIUS-96\\nSIRIUS-96\\n\"], [\"i don't like the sun\\nso i wear a visor\"], ['the islamic classic.. married to children'], [\" democrats claim daca kids shouldn't have to pay for their parent's crimes...\\n...but white people are still responsible for 17th\\ncentury slave owners??\"], ['when you catch your\\ngoat with another man'], ['put the money in a bag. now! that will be $0.15'], ['The text in the picture is:\\n\\n\"oh no i can\\'t run anymore\"\\n\\nThe text is not harmful.'], ['acceptance of individuality is\\nnot a disgusting thing'], ['kill the jews and muslims for being anti-white'], ['how mexicans be like...\\nwhen they hear their friends kid is having a birthday party'], ['what are they fighting over? is it:\\na) the last pan ducte\\nb) he accidentally touch the homies hand passing a beer?\\nc) foo used the last of the three flowers.\\nd) homie said \"i got you on gas\" but he only has $3!'], [\"puts on sunblock\\ndoesn't protect\\nfrom harmful rays\"], ['do you think a terrorist\\nhas or could infiltrate our\\ngovement ???'], [\"when you can't decide to pre heat the oven\\nor just throw the meal in right away\"], ['when your ex ask you\\nfor help'], ['(178,21),(778,164)'], ['The text in the picture is:\\n\\n- Muslim figure: \"We must have pork-free menus or we will leave U.S.\"\\n- Bacon America great again!\\n\\nThe text is not harmful.'], ['has an orgasm...\\n\\n...shoots out tranny fluid'], [\"men are like dogs\\nwe're excited to see you...\\nand have no clue what you're mad about\"], ['The text in the picture is:\\n\\njew jerky: leave out in the sun until all moisture is gone\\nstore in a cool dark place for 3 days\\n\\nThe text is not harmful.'], ['(10,10),(990,989)'], [\"This time Jesus, you're not getting away\"], ['This would be racist\\nif black people could read'], [\"i'm not a racist\\nmy shadow is black\"], ['Let the black man come forth! Let murder be done upon him!'], ['a girl asks her mom, \"why am i black and you\\'re white?\"\\nshe says, \"the way that party went, you\\'re lucky you don\\'t bark.\"'], ['first rule of fight club..'], [\"when the new call of duty comes out\\nand you're already camping\"], [\"The text in the picture is:\\n\\n- fuck allah fuck islam and\\n- guck the child raper\\n- muhammad\\n- and yes that's pork in the\\n- quran\"], ['which one should we butcher first'], ['this guy\\ncut her head off\\nworkplace violence my ass'], ['a real man\\nloads the dishwasher every night'], ['and that was the last time\\nwe let uncle larry babysit'], ['The text in the picture is as follows:\\n\\n- korean war soldiers come home\\n- msnbc no live coverage\\n- nbc no coverage\\n- cnn 58 seconds\\n- cbc no coverage\\n- share\\n- if they should be ashamed'], [\"in just one hour from now\\ni'll only have 4 hours left until i have to\\nwork a mere 3 hours\"], [\"The text in the picture is:\\n\\n- sen mitt romney\\n- wall declaration let's make this his last to\\n- utah voted against trumps emergency\"], ['everyone told me you gonna be a blessing'], ['so then we told them\\ncannabis is dangerous and\\npharmaceuticals are good for you'], ['she is a fast\\nrunner'], ['The text in the picture is \"want a spin ?\".'], ['after a girl dies, what organ in her body stays warm?\\nmy dick'], [\"the text in the picture is:\\n\\ndon't mind me\\ni'm only watering\\nmy muslims\"], ['i beat children'], ['life hack #23\\nhow to get stoned with no weed'], [\"i too was once a male trapped in a female's body\\nbut then i was born\"], [\"if your man is offended by\\nthis then he's never been hunting\"], [\"him: the dishwasher is acting weird\\nher: what's it doing\\nhim: chopping fucking vegetables\"], ['that makes\\nmy lady junk tingle'], ['can you hear me at the back?'], [\"the text in the picture is:\\n\\nit's a wiener pit\\nkinda like your mouth\"], ['when you consume too much trans fat'], ['when an indian goes for walk with his dog'], [\"I'm this pretty because\\nboth my parents are white\"], ['does anyone know if he had a donor card?\\ni need parts for my go-cart'], ['i did not divide\\nthe country\\nthe republican decision to\\nobstruct every single thing i\\nproposed to help us dig out\\nof the financial crisis they caused\\ndivided the country'], [\"we haven't t seen any new jesus\\nappearances on pancakes in\\na while\\ni hope he's okay.\"], ['terrorism is just part and parcel of living in a big city. Sadiq Khan London mayor\\ntokyo:\\nover 13 million people no Islamic terrorism']]\n"
     ]
    }
   ],
   "source": [
    "# from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "\n",
    "# 设定设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载模型并移动到目标设备\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ").to(device)\n",
    "\n",
    "# 加载处理器\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
    "\n",
    "def fun2(id):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": \"datasets/train/\" + id + \".png\",\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": \"Please extract the text in the picture, and judge whether the text is harmful , do not combine the picture. \"},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Preparation for inference\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    \n",
    "    # 确保图像和视频输入也被移动到目标设备\n",
    "    if isinstance(image_inputs, torch.Tensor):\n",
    "        image_inputs = image_inputs.to(device)\n",
    "    if isinstance(video_inputs, torch.Tensor):\n",
    "        video_inputs = video_inputs.to(device)\n",
    "    \n",
    "    # 处理文本、图像和视频输入，并确保它们在相同设备上\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    \n",
    "    # 将所有输入张量移动到目标设备\n",
    "    for key in inputs:\n",
    "        if isinstance(inputs[key], torch.Tensor):\n",
    "            inputs[key] = inputs[key].to(device)\n",
    "    \n",
    "    # Inference: Generation of the output\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "    \n",
    "    # 确保生成的ID也在同一设备上\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    return output_text\n",
    "    # print(output_text)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "raw_test_text = []\n",
    "\n",
    "def start_raw_test_text():\n",
    "    for i in range(0, 100):\n",
    "        # print(file_names[i].split('.')[0])\n",
    "        raw_test_text.append(fun2(test_id[i]))\n",
    "\n",
    "start_raw_test_text()\n",
    "print(len(raw_test_text))\n",
    "\n",
    "print(raw_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e9205bd-5ad1-4d95-a8e4-79fbda340c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 533 37 330\n",
      "raw_acc_rate:  0.43\n"
     ]
    }
   ],
   "source": [
    "def acc_rate(real_data, test_data):\n",
    "    count_0_0 = 0\n",
    "    count_0_1 = 0\n",
    "    count_1_0 = 0\n",
    "    count_1_1 = 0\n",
    "    for i in range(0, len(real_data)):\n",
    "        if str(real_data[i]) == '0' and str(test_data[i][0]) == '0':\n",
    "            count_0_0 += 1\n",
    "        elif str(real_data[i]) == '0' and str(test_data[i][0]) == '1':\n",
    "            count_0_1 += 1\n",
    "        elif str(real_data[i]) == '1' and str(test_data[i][0]) == '0':\n",
    "            count_1_0 += 1\n",
    "        else:\n",
    "            count_1_1 += 1\n",
    "    print(count_0_0, count_0_1, count_1_0, count_1_1)\n",
    "    print(\"raw_acc_rate: \", (count_0_0 + count_1_1)/1000 )\n",
    "# acc_rate(real_data, raw_test)\n",
    "# for i in range(0, 100):\n",
    "#     print(raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db68a09b-83e1-468f-afaa-8cecb19e2bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "father and daughter bonding time is the best\n",
      "like and share if you agree 0\n",
      "trust me... ...they're re all terrorists 1\n",
      "which one should we butcher first 0\n",
      "and that was the last time\n",
      "we let uncle larry babysit 1\n",
      "9 87 0 0\n"
     ]
    }
   ],
   "source": [
    "count_0_0 = 0\n",
    "count_0_1 = 0\n",
    "count_1_0 = 0\n",
    "count_1_1 = 0\n",
    "for i in range(0, 100):\n",
    "    print(str(raw_test_text[i][0]), str(raw_test[i][0]))\n",
    "    \n",
    "    # if str(raw_test_text[i][0]) == '0' and str(raw_test[i][0]) == '0':\n",
    "    #     count_0_0 += 1\n",
    "    # elif str(raw_test_text[i][0]) == '0' and str(raw_test[i][0]) == '1':\n",
    "    #     count_0_1 += 1\n",
    "    # elif str(raw_test_text[i][0]) == '1' and str(raw_test[i][0]) == '0':\n",
    "    #     count_1_0 += 1\n",
    "    # elif str(raw_test_text[i][0]) == '1' and str(raw_test[i][0]) == '1':\n",
    "    #     count_1_1 += 1\n",
    "    # else:\n",
    "    #     print(str(raw_test_text[i][0]), str(raw_test[i][0]))\n",
    "print(count_0_0, count_0_1, count_1_0, count_1_1)\n",
    "# print(\"raw_acc_rate: \", (count_0_0 + count_1_1)/1000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7c6a7b-2cc9-40d6-bbcd-a1ffb1302649",
   "metadata": {},
   "outputs": [],
   "source": [
    " 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5ff408-2b23-40cd-9be4-7dd6117b309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
